{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d57ae-0873-4006-b5ab-b7491dd5cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''hRnnPtLitIni_v1b3.ipynb [++++] A minimalist definition of RNNs using PyTorch and Lightning.\n",
    "''';\n",
    "# AUTHOR: Hendrik Mandelkow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d24da1-d95d-471c-87eb-3a65a6f99a1e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f088aa4-b902-4392-9334-21114ebba517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import lightning as pl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a1e0e-660a-40e8-a714-040fd4905529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hbarg(X,W=0.9):\n",
    "    X = np.r_['0,2',X]\n",
    "    N = len(X)\n",
    "    h = [ plt.bar(np.arange(x.size)+n*W/N-W/2+1,x,W/N,align='edge') for n,x in enumerate(X) ]\n",
    "    plt.xticks(np.arange(1,X[0].size+1))\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc155484-366f-4210-b430-82a57f73b4b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "hbarg = lambda X,W=0.9: [ plt.bar(np.arange(x.size)+n*W/len(X)-W/2.0+1,x,W/len(X),align='edge') for n,x in enumerate(X) ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a0ec9-8d11-41a6-a4dd-53085365905b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9c67ca8-e74f-4b4b-9277-2a8a7dd35ef0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataloader with only cloud object pre-initialized and only the list of files passed\n",
    "# import io\n",
    "\n",
    "class hPtDset(torch.utils.data.Dataset):\n",
    "    def __init__(self, N):\n",
    "        self.Files = Files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        Fname = self.Files[idx]\n",
    "        # Mat = h5.loadmat()\n",
    "        Mat = project.load_file(Fname,Type='f')\n",
    "        Mat = h5.loadmat( Mat, appendmat=False )\n",
    "        return Mat        \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "706f2a72-5242-49a1-99a3-a11780bb6029",
   "metadata": {
    "tags": []
   },
   "source": [
    "class hPtDset(torch.utils.data.IterableDataset):\n",
    "    '''Step function with random onset.'''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        x = np.arange(100).reshape(-1,1) > np.random.randint(50,100)\n",
    "        return x.astype(np.float32).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee12d30d-5e5b-49b6-ad46-f7ae85e3e43d",
   "metadata": {
    "tags": []
   },
   "source": [
    "def gensample():\n",
    "    '''Step function with random onset.'''\n",
    "    while True:\n",
    "        x = np.arange(100) > np.random.randint(50,100)\n",
    "        yield x.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "717bfa37-3a0f-4767-8e25-ae5c926e7169",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dload = torch.utils.data.DataLoader( hPtDset(), batch_size=4, shuffle=False )\n",
    "next(iter(Dload)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a9f77-2520-484b-ad97-88a481bfd20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyTorch Models RNN + RNN-AE\n",
    "1. declare Mdl a subclass of nn.Module\n",
    "2. declare all required layer objects as attribures Mdl.Layer1 = ...\n",
    "3. declare graph linking objects by defining forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44a073-a03b-40b1-8a99-353264e71748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class hRnn(torch.nn.Module):\n",
    "    def __init__(self, MdlPar, Base=None):\n",
    "        super().__init__()\n",
    "        self.MdlPar = MdlPar.copy()\n",
    "        #< self.Nt = Nt\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.lossfun = torch.nn.MSELoss() # default\n",
    "        \n",
    "        LayerCl = torch.nn.LSTM\n",
    "        LayerAct = torch.nn.Identity()\n",
    "        Bidir = False\n",
    "        \n",
    "        LayerNin = MdlPar[0]\n",
    "        for L in MdlPar[1:]:\n",
    "            if L in ['lstm']:\n",
    "                LayerCl = torch.nn.LSTM\n",
    "            elif L in ['gru']:\n",
    "                LayerCl = torch.nn.GRU\n",
    "            elif L in ['bidir']:\n",
    "                Bidir=True\n",
    "            elif L in ['linear']:\n",
    "                LayerCl = torch.nn.Linear\n",
    "            elif L in ['bilinear']:\n",
    "                LayerCl = torch.nn.Bilinear\n",
    "            elif L in ['relu']: \n",
    "                LayerAct = torch.nn.ReLU()\n",
    "            elif L in ['lelu']: \n",
    "                LayerAct = torch.nn.LeakyReLU(0.01)\n",
    "            elif L in ['tanh']: \n",
    "                LayerAct = torch.nn.Tanh()\n",
    "            elif L in ['ident','noact']: \n",
    "                LayerAct = torch.nn.Identity()\n",
    "            elif isinstance(L,int):\n",
    "                LayerNout = L if Base is None else Base**L\n",
    "                #< self.layers.append( LayerCl( input_size=LayerNin, hidden_size=LayerNout, num_layers=1, batch_first=True) )\n",
    "                # layer = LayerCl( input_size=LayerNin, hidden_size=LayerNout, num_layers=1, batch_first=True)\n",
    "                if LayerCl is torch.nn.Linear:\n",
    "                    layer = LayerCl( LayerNin, LayerNout )\n",
    "                    Bidir = False\n",
    "                elif LayerCl is torch.nn.Bilinear:\n",
    "                    layer = LayerCl( LayerNin, LayerNin, LayerNout )\n",
    "                    Bidir = False\n",
    "                else:\n",
    "                    # layer = LayerCl( input_size=LayerNin, hidden_size=LayerNout, num_layers=1, batch_first=True)\n",
    "                    layer = LayerCl( LayerNin, LayerNout, num_layers=1, batch_first=True, bidirectional=Bidir)\n",
    "                    #< print('Layer: ',layer)\n",
    "                    \n",
    "                layer.activation = LayerAct\n",
    "                self.layers.append( layer )\n",
    "                LayerNin = 2*LayerNout if Bidir else LayerNout\n",
    "                \n",
    "            elif re.match(r'\\d+',L):\n",
    "                LayerNout = int( re.match(r'\\d+',L)[0] ) # NB: match[0] = full match\n",
    "                Proj = int( re.search(r'\\dp(\\d+)',L)[1] ) if re.search(r'\\dp(\\d+)',L) else 0\n",
    "                Rep = int( re.search(r'\\dr(\\d+)',L)[1] ) if re.search(r'\\dr(\\d+)',L) else 1\n",
    "                layer = LayerCl( LayerNin, LayerNout, proj_size=Proj, num_layers=Rep, batch_first=True, bidirectional=Bidir)\n",
    "                layer.activation = LayerAct\n",
    "                self.layers.append( layer )\n",
    "                LayerNin = 2*LayerNout if Bidir else LayerNout\n",
    "                                \n",
    "            else: \n",
    "                raise ValueError('Illegal value in MdlPar.')\n",
    "\n",
    "            \n",
    "    def forward( self, x, Nt=None):\n",
    "        if Nt is None: # encoder!\n",
    "            # Could use np.r_['0,3,1',...]?!\n",
    "            if x.ndim < 2: x = x.unsqueeze(-1)\n",
    "            if x.ndim < 3: x = x.unsqueeze(0)\n",
    "        else: # decoder!\n",
    "            x = x.reshape(-1,1,x.shape[-1])\n",
    "            x = x.repeat( 1, Nt, 1)\n",
    "            \n",
    "        xhc = (x,)\n",
    "        for layer in self.layers:\n",
    "            # NOTE: Cannot use Sequential() model because of this funky output format!?:\n",
    "            # x, (h_n,c_n) = layer(x) # x(out)=[h_1,h_2,...,h_n]\n",
    "            #< x = layer(x) # x(out)=[h_1,h_2,...,h_n]\n",
    "            if isinstance( layer, torch.nn.Bilinear ):\n",
    "                xhc = layer( xhc[0], xhc[0])\n",
    "            else:\n",
    "                xhc = layer( xhc[0]) # x(out)=[h_1,h_2,...,h_n]\n",
    "            #< if isinstance(x,tuple): x, (h_n,c_n) = x\n",
    "            # if isinstance(x,tuple): x, hc = x\n",
    "            if isinstance(xhc,tuple): # +++ Make output uniform: a tuple of non-tuples\n",
    "                xhc = sum([ n if isinstance(n,tuple) else (n,) for n in xhc],())\n",
    "            else: \n",
    "                xhc = (xhc,)\n",
    "            xhc = ( layer.activation(xhc[0]), ) + xhc[1:]\n",
    "            #< x = layer.activation(x)\n",
    "            # try: x = layer.activation(x)\n",
    "            # except: pass\n",
    "            \n",
    "        # if Nt is None: return h_n\n",
    "        # else: return x\n",
    "        #< return x, h_n, c_n\n",
    "        #< return x, hc\n",
    "        return xhc\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def mdlpar2id(MdlPar):\n",
    "        '''[+++] Create model ID (str) for logging.'''\n",
    "        # MdlId = '-'.join( [str(n) for n in MdlPar[1:-3]]) # e.g. 16-8-4-8-16\n",
    "        ## More concise only 2^n units / layer\n",
    "        MdlId = ''.join( [ n[:2].capitalize() if isinstance(n,str) else str(int(np.log2(n))) for n in MdlPar[1:-3]])\n",
    "        return MdlId\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e1dffc4-4cdc-4dcb-b5e6-1bfe20e6b4bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "sum([ n if isinstance(n,tuple) else (n,) for n in (1,(2,3),4)],())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc618cf9-f2fc-41c2-ac94-f8e12c55b0f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mdl = hRnn([1,'lstm','relu',32,16,32,'linear','ident',1])\n",
    "Mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddafc7d2-eadf-4f06-8f10-6187266988cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hMdlPar2Id = lambda MdlPar: '-'.join( [str(n) for n in MdlPar[1:-3]])\n",
    "hMdlPar2Id = lambda MdlPar: ''.join( [ n[:2].capitalize() if isinstance(n,str) else str(int(np.log2(n))) for n in MdlPar[1:-3]])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "802db5c3-a8d2-4631-a1e7-04f8780652c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "pl.pytorch.loggers.CSVLogger??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5be11-f91c-4ca9-9f71-e812282152fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class hRnnAE(torch.nn.Module):\n",
    "    '''hRnnAE [1a1]\n",
    "    Automatically split input MdlPar for encoder and decoder RNN:\n",
    "    Mdl = hRnnAE( MdlPar = [1,'lstm','relu',32,16,32,'linear','ident',1] ) ->\n",
    "    -> Mdl.encoder = hRnn( MdlPar = [1,'lstm','relu',32,16] )\n",
    "    -> Mdl.encoder = hRnn( MdlPar = [16,'lstm','relu',32,'linear','ident',1] )\n",
    "    ''';\n",
    "    def __init__( self, MdlPar ):\n",
    "        super().__init__()\n",
    "        self.MdlPar = MdlPar # save for good measure\n",
    "        self.MdlId = self.mdlpar2id(self.MdlPar)\n",
    "        n = MdlPar.index( min( filter( lambda x: isinstance(x,int), MdlPar[1:-1]) ))\n",
    "        \n",
    "        self.encoder = hRnn(MdlPar[:n+1])\n",
    "        StrPar = list( filter( lambda x: isinstance(x,str), MdlPar[:n]) )\n",
    "        self.decoder = hRnn( MdlPar[n:n+1] + StrPar + MdlPar[n+1:])\n",
    "        \n",
    "        self.lossfun = torch.nn.MSELoss() # reduction=\"mean\" (default)\n",
    "        # self.lossfun = torch.nn.L1Loss() # reduction=\"mean\" (default)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        # self.lrscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( self.optimizer )\n",
    "        self.logger = pl.pytorch.loggers.CSVLogger('LitLog',self.MdlId,None,'',10) # root, name, version, prefix, flush\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xhc = self.encoder(x)\n",
    "        Nt = xhc[0].shape[-2]\n",
    "        xhc = self.decoder(xhc[1], Nt)\n",
    "        return xhc[0]\n",
    "    \n",
    "    \n",
    "    def fit( self, train_set, valid_set=None, lossfun=None, optimizer=None, lrscheduler=None, device=None):\n",
    "        # if optimizer is None: \n",
    "        # self.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        # lossfun = MSELoss(reduction=\"sum\")\n",
    "        # if device is None: device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # +++\n",
    "        # model.to(device)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def mdlpar2id(MdlPar):\n",
    "        MdlId = '-'.join( [str(n) for n in MdlPar[1:-3]])\n",
    "        MdlId = ''.join( [ n[:2].capitalize() if isinstance(n,str) else str(int(np.log2(n))) for n in MdlPar[1:-3]])\n",
    "        return MdlId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f6779-81cd-4e8b-a8a5-e6c9f1406cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class hRnnAE2(torch.nn.Module):\n",
    "    '''hRnnAE [2a1]\n",
    "    Use separate inputs for encoder and decoder RNN:\n",
    "    ''';\n",
    "    def __init__( self, EncPar, DecPar ):\n",
    "        super().__init__()\n",
    "        assert EncPar[-1] == DecPar[0], 'Oops! Encoder output must equal decoder input.'\n",
    "        self.EncPar = EncPar # save for good measure\n",
    "        self.DecPar = DecPar # save for good measure        \n",
    "        self.encoder = hRnn( EncPar )\n",
    "        self.decoder = hRnn( DecPar )\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.lossfun = torch.nn.MSELoss() # reduction=\"mean\" (default)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xhc = self.encoder(x)\n",
    "        Nt = xhc[0].shape[-2]\n",
    "        xhc = self.decoder(xhc[1], Nt)\n",
    "        return xhc[0]\n",
    "    \n",
    "    \n",
    "    def fit( self, train_set, valid_set=None, optimizer=None, lossfun=None, device=None):\n",
    "        # if optimizer is None: \n",
    "        # self.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        # lossfun = MSELoss(reduction=\"sum\")\n",
    "        # if device is None: device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # +++\n",
    "        # model.to(device)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea7e9c78-2e02-4c42-9891-6a54febc54ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mdl = hRnn([1,'lstm','relu',32,16,32,'linear','ident',1])\n",
    "Mdl"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0cf4648b-3296-44a6-bab9-21e4a261505d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mdl = hRnnAE([1,'lstm','relu',32,16,32,'linear','ident',1])\n",
    "Mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd90b0f-fd7e-4b87-863b-639b277f4149",
   "metadata": {},
   "source": [
    "# Lightning wrapper"
   ]
  },
  {
   "cell_type": "raw",
   "id": "539a8653-2197-4f70-8573-f4e4ccdc4dbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## hRnnAE as LightningModule instead of torch.Module:\n",
    "class hRnnAeLit(pl.LightningModule):\n",
    "    def __init__( self, MdlPar ):\n",
    "        super().__init__()\n",
    "        ## Find the bottleneck encoding layer:\n",
    "        n = MdlPar.index( min( filter( lambda x: isinstance(x,int), MdlPar[1:-1]) ))\n",
    "        self.encoder = hRnn(MdlPar[:n+1])\n",
    "        self.decoder = hRnn(MdlPar[n:])        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3) # -> config._opt.\n",
    "        self.lossfun = torch.nn.MSELoss(reduction=\"sum\") # +++ ***\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, h_n, c_n = self.encoder(x)\n",
    "        Nt = x.shape[-2]\n",
    "        x, h_n, c_n = self.decoder(h_n, Nt)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. it is independent of forward\n",
    "        x, y = batch\n",
    "        yh = self.forward(x) # or self(x)\n",
    "        loss = self.lossfun(yh, y)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"Tloss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        #< return torch.optim.Adam( self.parameters(), lr=1e-3)\n",
    "        return self.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70cbbbb-166d-4ce7-a368-5873ab785eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Simpler: Just wrap hRnnAE\n",
    "class hMdlLit(pl.LightningModule):\n",
    "    def __init__( self, Mdl, **props ):\n",
    "        super().__init__()\n",
    "        self.model = Mdl\n",
    "        self.__dict__.update( **props )\n",
    "        self.save_hyperparameters() # saves attributes of self\n",
    "        # self.save_hyperparameters(ignore=['Mdl']) # why Mdl and not \"model\"?!?\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        '''training_step returns the loss for one batch.\n",
    "        The rest of the training loop is handled by Lightning implicitly.\n",
    "        '''\n",
    "        if isinstance( batch, (tuple,list)):\n",
    "            x, y = batch\n",
    "        else:\n",
    "            x = batch\n",
    "            y = x # autoencoder\n",
    "            \n",
    "        yh = self(x)\n",
    "        if isinstance( yh, (tuple,list)): yh = yh[0]\n",
    "        \n",
    "        loss = self.model.lossfun(yh, y)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"Tloss\", loss, prog_bar=True)\n",
    "        # self.log(\"Tloss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        '''Return optimizer obj(s) and (optionally) a LR scheduler(s) obj as list or dict.'''\n",
    "        #< return torch.optim.Adam( self.parameters(), lr=1e-3)\n",
    "        #< scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.2, patience=20, min_lr=5e-5)\n",
    "        optimizer = getattr(self,'optimizer',None)\n",
    "        if optimizer is None: optimizer = getattr(self.model,'optimizer',None)\n",
    "        assert optimizer, 'Oops! No opimizer found in self.optimizer or self.model.optimizer?!?'\n",
    "        scheduler = getattr(self,'scheduler',None)\n",
    "        if scheduler is None: scheduler = getattr(self.model,'scheduler',None)\n",
    "        if scheduler is None:\n",
    "            return optimizer\n",
    "        else:\n",
    "            return optimizer, scheduler\n",
    "\n",
    "    \n",
    "    def validation_step( self, batch, batch_idx):\n",
    "        '''Compute any validation metrics or results and return, log or store them.\n",
    "        ''';\n",
    "        #x, y = batch\n",
    "        x = batch\n",
    "        xh = self(x)\n",
    "        loss = self.model.lossfun(xh, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"Vloss\", loss, prog_bar=True)\n",
    "        # self.log(\"Tloss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "#     def test_step(self,...): # model.test() == model.test_step()\n",
    "    \n",
    "#     def predict_step(self,...): # if undefined == forward()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f2606d3-d1d3-49fb-aad3-0181fcd6b2a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inastantiate PT model hRnnAE\n",
    "Mdl = hRnnAE([1,'lstm','relu',32,16,32,'linear','ident',1])\n",
    "# Mdl"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4eb7978d-1cc7-47ba-b851-d6177830a697",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mdl.MdlPar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6cd9b6d8-129c-4159-b085-0249fd78b5bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wrap model in Lightning\n",
    "# MdlLit = hMdlLit( Mdl )\n",
    "MdlLit = hMdlLit( Mdl, MdlPar=Mdl.MdlPar )\n",
    "# MdlLit"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74144338-c1ed-436d-91ce-6da007c46081",
   "metadata": {
    "tags": []
   },
   "source": [
    "MdlLit.MdlPar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf0c0992-97ab-4c48-983b-f071210224eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "MdlLit.model.MdlPar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f5917-bf62-4f8b-8434-947111695458",
   "metadata": {},
   "source": [
    "## Test with random data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb89513d-279b-4e43-b046-70c2036752ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MinVlossCb = pl.pytorch.callbacks.ModelCheckpoint( monitor='Vloss') # defaults to min save_top_k=1\n",
    "# MinVlossCb = pl.pytorch.callbacks.ModelCheckpoint( monitor='Vloss', filename='MinVloss') # defaults to min save_top_k=1\n",
    "MinVlossCb = pl.pytorch.callbacks.ModelCheckpoint( monitor='Vloss', dirpath='lightning_logs/tmp/', filename='MinVloss') # defaults to min save_top_k=1\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a970f57f-12ed-49c2-9b5f-fc068f525da9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Tdata = torch.tensor( np.random.rand(20,4,8,1) ).float()\n",
    "trainer = pl.Trainer(max_epochs=4, val_check_interval=None, callbacks=[MinVlossCb])\n",
    "# trainer.fit( MdlLit, train_dataloaders=Tdata)\n",
    "trainer.fit( MdlLit, Tdata, Tdata)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a37e2f01-cddc-47bd-9252-bb5bf4315dda",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HOWTO continue training of PyTorch Lightning model from checkpoint ckpt_path.\n",
    "# Note that the max_epochs > than previous epochs!\n",
    "trainer = pl.Trainer(max_epochs=8, val_check_interval=None, callbacks=[MinVlossCb])\n",
    "trainer.fit( MdlLit, Tdata, Tdata, ckpt_path='lightning_logs/tmp/MinVloss.ckpt')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13741314-2c41-4afa-ab9e-fd9b609bcbd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "MinVlossCb.best_model_path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8292781f-d1c1-4aec-bbc0-dabf0ae87444",
   "metadata": {
    "tags": []
   },
   "source": [
    "#< tmp = torch.load('lightning_logs/version_0/checkpoints/epoch=2-step=60.ckpt')\n",
    "tmp = torch.load(MinVlossCb.best_model_path)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08784016-1aff-4013-af99-986566c67bdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "tmp['hyper_parameters']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
